{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4800c042-c9ba-4d80-8785-ddd9a60ec160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3329569-204b-45f2-bd48-a7e2f72fc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CourseSearchSystem:\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "            \n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"Mean pooling to get sentence embeddings\"\"\"\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def get_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Get embeddings for a list of texts\"\"\"\n",
    "        encoded_input = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        encoded_input = {k: v.to(self.device) for k, v in encoded_input.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "\n",
    "        sentence_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        \n",
    "        return sentence_embeddings.cpu().numpy()\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and standardize text data\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = str(text)\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = ' '.join(text.split())\n",
    "        return text.lower()\n",
    "    \n",
    "    def prepare_course_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Prepare and clean course data\"\"\"\n",
    "        free_courses = df[df['Course Name'].str.contains('Free', case=False, na=False)]\n",
    "        \n",
    "        free_courses['search_text'] = free_courses['Course Name'].apply(self.preprocess_text)\n",
    "        \n",
    "        return free_courses\n",
    "    \n",
    "    def load_and_prepare_data(self, df: pd.DataFrame):\n",
    "        \"\"\"Load and prepare the course data and generate embeddings\"\"\"\n",
    "        self.courses_df = self.prepare_course_data(df)\n",
    "        self.course_embeddings = self.get_embeddings(self.courses_df['search_text'].tolist())\n",
    "\n",
    "    def generate_response(self, query: str, results: List[Dict]) -> str:\n",
    "        \"\"\"Generate a professional response with course recommendations\"\"\"\n",
    "        response_parts = []\n",
    "        \n",
    "        # Introduction based on number of results\n",
    "        if len(results) == 1:\n",
    "            response_parts.append(f\"I found an excellent free course matching your search for '{query}':\")\n",
    "        else:\n",
    "            response_parts.append(f\"I found {len(results)} relevant free courses matching your search for '{query}':\")\n",
    "        \n",
    "        # Course details\n",
    "        for i, result in enumerate(results, 1):\n",
    "            course_name = result['course_name']\n",
    "            course_section = f\"\\n**{i}. {course_name}**\\n\"\n",
    "            \n",
    "            # Add relevance score as a percentage\n",
    "            similarity_percentage = int(result['similarity_score'] * 100)\n",
    "            course_section += f\"\\n**Match Score:** {similarity_percentage}%\"\n",
    "            \n",
    "            # Add course link\n",
    "            course_section += f\"\\n\\n[Start Course]({result['url']})\\n\"\n",
    "            \n",
    "            response_parts.append(course_section)\n",
    "        \n",
    "        # Add helpful conclusion\n",
    "        response_parts.append(\"\\n---\\n\")\n",
    "        response_parts.append(\"**Notes:**\")\n",
    "        response_parts.append(\"• Courses are sorted by relevance to your search\")\n",
    "        response_parts.append(\"• All courses are free and include hands-on projects\")\n",
    "        response_parts.append(\"• Certificates are provided upon completion\")\n",
    "        \n",
    "        return \"\\n\".join(response_parts)\n",
    "    \n",
    "    def search_courses(self, query: str, top_k: int = 5) -> str:\n",
    "        \"\"\"Search for courses and return formatted response\"\"\"\n",
    "        query = self.preprocess_text(query)\n",
    "        query_embedding = self.get_embeddings([query])[0]\n",
    "        similarities = np.dot(self.course_embeddings, query_embedding)\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            course = self.courses_df.iloc[idx]\n",
    "            results.append({\n",
    "                'course_name': course['Course Name'],\n",
    "                'similarity_score': similarities[idx],\n",
    "                'url': course['Website']\n",
    "            })\n",
    "        \n",
    "        return self.generate_response(query, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87c05b-0684-409b-a24b-5c1c99eaf2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
